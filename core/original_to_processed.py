import glob
import json
import os

import cv2
import face_recognition
from minio.error import S3Error

from config import logger
from core.process import mosaic
from interface.minio_client import minio_client, BUCKET_NAME, download_from_minio, upload_to_minio
from model.processed_message import ProcessedVideoResult, VideoMetadata
from util.ffmpeg import get_video_info_ffprobe
from util.model_loader import ModelLoader
from util.state_manager import state_manager

# YOLO ë° FaceMesh ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
model = ModelLoader.get_yolo_model()
mp_face_mesh = ModelLoader.get_mp_face_mesh()



def download_target_images_from_minio(uuid, target_image_local_path):
    """MinIOì—ì„œ target í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    try:
        # MinIO ë²„í‚· ë‚´ target í´ë”ì˜ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        objects = minio_client.list_objects(BUCKET_NAME, prefix=f"{uuid}/target/", recursive=True)

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(target_image_local_path, exist_ok=True)

        for obj in objects:
            if obj.is_dir:
                continue  # ë””ë ‰í† ë¦¬ëŠ” ê±´ë„ˆëœ€

            # ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            file_name = os.path.basename(obj.object_name)
            local_file_path = os.path.join(target_image_local_path, file_name)
            minio_client.fget_object(BUCKET_NAME, obj.object_name, local_file_path)

            logger.info(f"Downloaded {obj.object_name} to {local_file_path}")

    except S3Error as e:
        logger.error(f"MinIO download error: {e}")
        return False
    except Exception as e:
        logger.error(f"Unexpected error while downloading target images: {e}")
        return False

    return True



def process_blurring_request(message):
    """Kafka ë©”ì‹œì§€ì—ì„œ split ìš”ì²­ì„ ì²˜ë¦¬"""
    try:
        uuid = message.get("video_id")
        bucket_name = message.get("bucket_name", "di-bucket")
        output_dir = os.path.join("output", uuid)

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)

        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        original_local_path = os.path.join(output_dir, "original.mp4")
        processed_local_path = os.path.join(output_dir, "processed.mp4")
        metadata_local_path = os.path.join(output_dir, "metadata.json")

        print("Processing split operation...")

        # TODO: mp4 í™•ì¥ìê°€ ì•„ë‹ˆë¼ë©´ ffmpegë¡œ ë³€ê²½ í•´ì£¼ëŠ” í•¨ìˆ˜ (opencvê°€ mp4, avi ë“± ì¼ë¶€ í™•ì¥ìì—ì„œë§Œ ì‘ë™, mkv, mov, webmì€ ì‹¤íŒ¨í•  í™•ë¥  ë†’ìŒ)
        # convert_to_mp4

        # temp ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)
        # ì›ë³¸ ì˜ìƒ ë‹¤ìš´ë¡œë“œ
        download_from_minio(f"{uuid}/original.mp4", original_local_path)

        # target í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        target_image_local_path = os.path.join(output_dir, "target_images")
        os.makedirs(target_image_local_path, exist_ok=True)

        download_success = download_target_images_from_minio(uuid, target_image_local_path)

        if not download_success:
            logger.error("Failed to download target images from MinIO.")
            return {"status": "error", "message": "Failed to download target images from MinIO"}

        # target_images ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        reference_image_paths = glob.glob(os.path.join(target_image_local_path, "*"))
        reference_encodings = []

        for reference_image_path in reference_image_paths:
            reference_image = face_recognition.load_image_file(reference_image_path)
            encodings = face_recognition.face_encodings(reference_image, num_jitters=10)

            if not encodings:
                logger.debug(f"Error: ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ {reference_image_path}. í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                continue

            reference_encodings.append(encodings[0])
            logger.debug(f"ì–¼êµ´ ì¸ì½”ë”© ë¡œë“œ ì™„ë£Œ : {reference_image_path}")

        if not reference_encodings:
            logger.debug("ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤! í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return {"status": "error", "message": "No valid reference encodings available"}

        # ì˜ìƒ ì²˜ë¦¬ ë° JSON ìƒì„±
        json_output_path, total_frames, fps, width, height, duration = process_video(original_local_path, processed_local_path, reference_encodings)

        # ì²˜ë¦¬ëœ ì˜ìƒ ë° JSON ì—…ë¡œë“œ
        upload_to_minio(processed_local_path, f"{uuid}/processed.mp4")
        upload_to_minio(json_output_path, f"{uuid}/metadata.json")


        return {
            "status": "success",
            "video_id": uuid,
            "processed_video_url": f"http://localhost:9000/{BUCKET_NAME}/{uuid}/processed.mp4",
            "metadata_url": f"http://localhost:9000/{BUCKET_NAME}/{uuid}/metadata.json",
            "message": "Video processed and uploaded",
            "video_metadata": {
                "width": width,
                "height": height,
                "total_frames": total_frames,
                "fps": fps,
                "duration": duration
            }
        }

        # return ProcessedVideoResult(
        #     status = "success",
        #     video_id = uuid,
        #     processed_video_url = f"http://localhost:9000/{BUCKET_NAME}/{uuid}/processed.mp4",
        #     metadata_url = f"http://localhost:9000/{BUCKET_NAME}/{uuid}/metadata.json",
        #     message = "Video processed and uploaded",
        #     video_metadata = VideoMetadata(width=width, height=height,total_frames=total_frames, fps=fps, duration=duration)
        #
        # )

    except Exception as e:
        return ProcessedVideoResult(
            status="error",
            video_id=uuid,
            processed_video_url="",
            metadata_url="",
            message=str(e),
            video_metadata=VideoMetadata(width=0, height=0, fps=0, total_frames=0, duration=0.0)
        )

def process_video(input_path, output_path, reference_encodings, tolerance=0.55):
    """split ì‹œ ì›ë³¸ ì˜ìƒì„ ì²˜ë¦¬í•˜ì—¬ processed.mp4 ë° metadata.json ìƒì„±"""
    state_manager.frames = []  # í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    state_manager.processed_frames = []  # í¸ì§‘ëœ í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        print("Error: Could not open video.")
        return None

    # FFmpegì„ ì‚¬ìš©í•˜ì—¬ ì´ í”„ë ˆì„ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    total_frames, duration = get_video_info_ffprobe(input_path)
    # total_frames = 1
    # duration = 1.1

    # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    print(f"ğŸ“Œ ì˜ìƒ ì •ë³´: ì´ {total_frames} í”„ë ˆì„, ì˜ìƒ ê¸¸ì´ : {duration} ,FPS: {fps}, í•´ìƒë„: {width}x{height}")

    # ì €ì¥í•  ë¹„ë””ì˜¤ ì„¤ì •
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    sequence_data = []  # JSON ì €ì¥ì„ ìœ„í•œ ë°ì´í„°

    frame_seq = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_seq += 1  # ì •í™•í•œ í”„ë ˆì„ ë²ˆí˜¸ ìœ ì§€
        frame_info = {"seq": frame_seq, "person": []}

        results = model(frame, conf=0.4)  # YOLO ê°ì§€ ì‹¤í–‰
        detections = results[0].boxes

        for detection in detections:
            x1, y1, x2, y2 = map(int, detection.xyxy[0])
            x1, y1, x2, y2 = max(0, x1 - 10), max(0, y1 - 10), min(width, x2 + 10), min(height, y2 + 10)
            face_image = frame[y1:y2, x1:x2]

            if face_image.shape[0] < 20 or face_image.shape[1] < 20:
                frame = mosaic(frame, (x1, y1, x2 - x1, y2 - y1))
                frame_info["person"].append({"x1": x1, "x2": x2, "y1": y1, "y2": y2})
                continue

            face_location = [(y1, x2, y2, x1)]
            face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_location, num_jitters=5)

            if face_encodings:
                face_encoding = face_encodings[0]
                matches = face_recognition.compare_faces(reference_encodings, face_encoding, tolerance=tolerance)
                if True in matches:
                    continue

            frame = mosaic(frame, (x1, y1, x2 - x1, y2 - y1))
            frame_info["person"].append({"x1": x1, "x2": x2, "y1": y1, "y2": y2})

        sequence_data.append(frame_info)
        out.write(frame)  # ëª¨ìì´í¬ ì²˜ë¦¬ëœ í”„ë ˆì„ ì €ì¥

    cap.release()
    out.release()

    # JSON ë°ì´í„° ì €ì¥
    json_output_path = output_path.replace(".mp4", ".json")
    with open(json_output_path, "w") as json_file:
        json.dump({"sequence": sequence_data, "total_frames": total_frames, "fps": fps, "width" : width, "height" : height, "duration" : duration}, json_file, indent=4)

    logger.debug(f"Processed video saved as {output_path}")
    logger.debug(f"JSON metadata saved as {json_output_path}")

    return json_output_path, total_frames, fps, width, height, duration

