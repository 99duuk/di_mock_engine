import os
import cv2
import json
from ultralytics import YOLO
import face_recognition
from kafka import KafkaConsumer, KafkaProducer
from Interface.minio_client import download_from_minio, upload_to_minio
from util.ffmpeg import get_frame_count_ffprobe
import mediapipe as mp
import subprocess
import logging
import sys

# --------------------------------------------------------------------------------------------------------------

# ë¡œê¹… ì„¤ì •
def setup_logging():
    """ë¡œê¹… ì„¤ì •ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler('video_processing.log')
        ]
    )
    return logging.getLogger(__name__)

logger = setup_logging()

# --------------------------------------------------------------------------------------------------------------

# YOLO ëª¨ë¸ ë° MediaPipe ì´ˆê¸°í™”
model = YOLO('yolov8m-face-lindevs.pt')
mp_face_mesh = mp.solutions.face_mesh.FaceMesh()

# --------------------------------------------------------------------------------------------------------------

# ì „ì—­ ë³€ìˆ˜
boxes = []  # ë°•ìŠ¤ ì¢Œí‘œë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
frames = []  # ì›ë³¸ í”„ë ˆì„ì„ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
processed_frames = []  # í¸ì§‘ëœ í”„ë ˆì„ì„ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
current_frame_idx = 0  # í˜„ì¬ í”„ë ˆì„ ì¸ë±ìŠ¤
export_requested = False  # ë‚´ë³´ë‚´ê¸° ìš”ì²­

# --------------------------------------------------------------------------------------------------------------

# ëª¨ìì´í¬ ì²˜ë¦¬
def mosaic(img, rect, size=15):
    """ì–¼êµ´ ì˜ì—­ì— ëª¨ìì´í¬ ì²˜ë¦¬."""
    (x, y, w, h) = rect
    sub_img = img[y:y + h, x:x + w]
    sub_img = cv2.resize(sub_img, (size, size), interpolation=cv2.INTER_LINEAR)
    mosaic_img = cv2.resize(sub_img, (w, h), interpolation=cv2.INTER_LINEAR)
    img[y:y + h, x:x + w] = mosaic_img
    return img

# --------------------------------------------------------------------------------------------------------------



def process_video(input_path, output_path, reference_encodings, tolerance=0.55):
    """split ì‹œ ì›ë³¸ ì˜ìƒì„ ì²˜ë¦¬í•˜ì—¬ processed.mp4 ë° metadata.json ìƒì„±"""
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        print("Error: Could not open video.")
        return None

    # FFmpegì„ ì‚¬ìš©í•˜ì—¬ ì´ í”„ë ˆì„ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    total_frames = get_frame_count_ffprobe(input_path)

    # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    print(f"ğŸ“Œ ì˜ìƒ ì •ë³´: ì´ {total_frames} í”„ë ˆì„, FPS: {fps}, í•´ìƒë„: {width}x{height}")

    # ì €ì¥í•  ë¹„ë””ì˜¤ ì„¤ì •
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    sequence_data = []  # JSON ì €ì¥ì„ ìœ„í•œ ë°ì´í„°

    frame_seq = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_seq += 1  # ì •í™•í•œ í”„ë ˆì„ ë²ˆí˜¸ ìœ ì§€
        frame_info = {"seq": frame_seq, "person": []}

        results = model(frame, conf=0.4)  # YOLO ê°ì§€ ì‹¤í–‰
        detections = results[0].boxes

        for detection in detections:
            x1, y1, x2, y2 = map(int, detection.xyxy[0])
            x1, y1, x2, y2 = max(0, x1 - 10), max(0, y1 - 10), min(width, x2 + 10), min(height, y2 + 10)
            face_image = frame[y1:y2, x1:x2]

            if face_image.shape[0] < 20 or face_image.shape[1] < 20:
                frame = mosaic(frame, (x1, y1, x2 - x1, y2 - y1))
                frame_info["person"].append({"x1": x1, "x2": x2, "y1": y1, "y2": y2})
                continue

            face_location = [(y1, x2, y2, x1)]
            face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_location, num_jitters=5)

            if face_encodings:
                face_encoding = face_encodings[0]
                matches = face_recognition.compare_faces(reference_encodings, face_encoding, tolerance=tolerance)
                if True in matches:
                    continue

            frame = mosaic(frame, (x1, y1, x2 - x1, y2 - y1))
            frame_info["person"].append({"x1": x1, "x2": x2, "y1": y1, "y2": y2})

        sequence_data.append(frame_info)
        out.write(frame)  # ëª¨ìì´í¬ ì²˜ë¦¬ëœ í”„ë ˆì„ ì €ì¥

    cap.release()
    out.release()

    # JSON ë°ì´í„° ì €ì¥
    json_output_path = output_path.replace(".mp4", ".json")
    with open(json_output_path, "w") as json_file:
        json.dump({"sequence": sequence_data, "total_frames": total_frames, "fps": fps}, json_file, indent=4)

    print(f"ğŸ“Œ Processed video saved as {output_path}")
    print(f"ğŸ“Œ JSON metadata saved as {json_output_path}")

    return json_output_path

# --------------------------------------------------------------------------------------------------------------

def compare_metadata(original_metadata_path, edited_metadata_path):
    """
    ê¸°ì¡´ metadata.jsonê³¼ edited_metadata.jsonì„ ë¹„êµí•˜ì—¬ ëª¨ìì´í¬ ì¶”ê°€/ì œê±°ê°€ í•„ìš”í•œ ë¶€ë¶„ì„ ì°¾ìŒ.
    """
    logger.info(f"Comparing metadata files: {original_metadata_path} and {edited_metadata_path}")

    # JSON íŒŒì¼ ì½ê¸°
    with open(original_metadata_path, 'r') as f:
        original_data = json.load(f)  # ì›ë³¸ metadata ë¡œë“œ

    with open(edited_metadata_path, 'r') as f:
        edited_data = json.load(f)  # í¸ì§‘ëœ metadata ë¡œë“œ

    tasks = []  # ìˆ˜í–‰í•´ì•¼ í•  ì‘ì—… ëª©ë¡

    # metadata.jsonê³¼ edited_metadata.jsonì„ dict í˜•íƒœë¡œ ë³€í™˜
    original_dict = {seq_data["seq"]: seq_data["person"] for seq_data in original_data["sequence"]}
    edited_dict = {seq_data["seq"]: seq_data["person"] for seq_data in edited_data["sequence"]}

    for seq_number, edited_boxes in edited_dict.items():
        orig_boxes = original_dict.get(seq_number, [])

        remove_boxes = []  # ì œê±°í•  ì˜ì—­
        add_boxes = []  # ì¶”ê°€í•  ì˜ì—­

        for edited in edited_boxes:
            ex1, ex2, ey1, ey2 = edited["x1"], edited["x2"], edited["y1"], edited["y2"]
            found_exact_match = False  # ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” ì¢Œí‘œ ì—¬ë¶€ í™•ì¸

            for meta in orig_boxes:
                mx1, mx2, my1, my2 = meta["x1"], meta["x2"], meta["y1"], meta["y2"]

                #  Aê°€ ì •í™•íˆ ì¡´ì¬í•˜ë©´ ì „ì²´ ì œê±°
                if (mx1 == ex1 and mx2 == ex2 and my1 == ey1 and my2 == ey2):
                    found_exact_match = True
                    remove_boxes.append(edited)  # ì •í™•í•œ ì¼ì¹˜ë§Œ ì œê±°
                    continue

                #  A âˆ© B (êµì§‘í•©) í™•ì¸
                ix1 = max(mx1, ex1)
                iy1 = max(my1, ey1)
                ix2 = min(mx2, ex2)
                iy2 = min(my2, ey2)

                if ix1 < ix2 and iy1 < iy2:
                    #  (A U B) - Aì˜ ì°¨ì§‘í•© ì—°ì‚° ìˆ˜í–‰
                    # **ê²¹ì¹œ ë¶€ë¶„ì„ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ë¥¼ ì œê±°**
                    new_meta_boxes = []

                    if mx1 < ix1:  # Aì˜ ì™¼ìª½ ë¶€ë¶„ ì œê±°
                        remove_boxes.append({"x1": mx1, "x2": ix1, "y1": my1, "y2": my2})
                    else:
                        new_meta_boxes.append({"x1": mx1, "x2": ix1, "y1": my1, "y2": my2})

                    if mx2 > ix2:  # Aì˜ ì˜¤ë¥¸ìª½ ë¶€ë¶„ ì œê±°
                        remove_boxes.append({"x1": ix2, "x2": mx2, "y1": my1, "y2": my2})
                    else:
                        new_meta_boxes.append({"x1": ix2, "x2": mx2, "y1": my1, "y2": my2})

                    if my1 < iy1:  # Aì˜ ìœ„ìª½ ë¶€ë¶„ ì œê±°
                        remove_boxes.append({"x1": mx1, "x2": mx2, "y1": my1, "y2": iy1})
                    else:
                        new_meta_boxes.append({"x1": mx1, "x2": mx2, "y1": iy1, "y2": my2})

                    if my2 > iy2:  # Aì˜ ì•„ë˜ìª½ ë¶€ë¶„ ì œê±°
                        remove_boxes.append({"x1": mx1, "x2": mx2, "y1": iy2, "y2": my2})
                    else:
                        new_meta_boxes.append({"x1": mx1, "x2": mx2, "y1": my1, "y2": iy2})

                    #  êµì§‘í•© ë¶€ë¶„ì„ ë‹¤ì‹œ ì¶”ê°€
                    for box in new_meta_boxes:
                        if box["x1"] < box["x2"] and box["y1"] < box["y2"]:
                            add_boxes.append(box)

        # ê¸°ì¡´ `metadata` ì¢Œí‘œë¥¼ ìœ ì§€í•˜ê³ , ìƒˆë¡œìš´ ì¢Œí‘œë§Œ ì¶”ê°€í•´ì•¼ í•¨
        orig_set = {tuple((p["x1"], p["x2"], p["y1"], p["y2"])) for p in orig_boxes}
        edited_set = {tuple((p["x1"], p["x2"], p["y1"], p["y2"])) for p in edited_boxes}
        add_boxes.extend([{"x1": x1, "x2": x2, "y1": y1, "y2": y2} for (x1, x2, y1, y2) in (edited_set - orig_set)])

        # **ë””ë²„ê¹…: ì‚­ì œ ë° ì¶”ê°€ ë°•ìŠ¤ ì •ë³´ ì¶œë ¥**
        logger.debug(f"Frame {seq_number} REMOVE {remove_boxes}")
        logger.debug(f"Frame {seq_number} ADD {add_boxes}")

        # ë³€ê²½ì‚¬í•­ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ tasks ì¶”ê°€
        if remove_boxes or add_boxes:
            tasks.append({
                "seq": seq_number,  # í”„ë ˆì„ ë²ˆí˜¸
                "remove": remove_boxes,  # ê¸°ì¡´ ëª¨ìì´í¬ ì œê±°
                "add": add_boxes  # ìƒˆë¡­ê²Œ ì¶”ê°€í•  ëª¨ìì´í¬
            })
            logger.info(f"Frame {seq_number}: {len(remove_boxes)} boxes to remove, {len(add_boxes)} boxes to add")

    logger.info(f"Total tasks found: {len(tasks)}")
    return tasks

# --------------------------------------------------------------------------------------------------------------

def join_frame(frames, fps, output_path):
    """
    ì—°ì†ëœ í”„ë ˆì„ë“¤ì„ í•˜ë‚˜ì˜ ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        frames (list): ë¹„ë””ì˜¤ë¡œ ë§Œë“¤ í”„ë ˆì„ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        fps (int): ì¶œë ¥ ë¹„ë””ì˜¤ì˜ ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜
        output_path (str): ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

    Returns:
        str: ìƒì„±ëœ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ì‹¤íŒ¨ ì‹œ None
    """
    if not frames:
        return None

    # ì²« ë²ˆì§¸ í”„ë ˆì„ì—ì„œ ë¹„ë””ì˜¤ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
    height, width = frames[0].shape[:2]

    # VideoWriter ì„¤ì •
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MP4 ì½”ë± ì„¤ì •
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    # ê° í”„ë ˆì„ì„ ë¹„ë””ì˜¤ì— ì“°ê¸°
    for frame in frames:
        out.write(frame)

    out.release()  # ë¹„ë””ì˜¤ íŒŒì¼ ë‹«ê¸°
    return output_path

# --------------------------------------------------------------------------------------------------------------

def process_frame(original_video, processed_video, tasks):
    """í”„ë ˆì„ë³„ë¡œ ëª¨ìì´í¬ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì œê±°í•©ë‹ˆë‹¤."""
    logger.info(f"Processing frames with {len(tasks)} tasks")
    cap_orig = cv2.VideoCapture(original_video)
    cap_proc = cv2.VideoCapture(processed_video)

    if not cap_orig.isOpened() or not cap_proc.isOpened():
        logger.error("Failed to open video files")
        return []

    edited_frames = []  # í¸ì§‘ëœ í”„ë ˆì„ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    frame_map = {}  # ì¤‘ë³µ ì €ì¥ ë°©ì§€ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    current_seq = 1  # í˜„ì¬ í”„ë ˆì„ ë²ˆí˜¸

    # ì—°ì†ëœ "No task found" ë¡œê¹…ì„ ìœ„í•œ ë³€ìˆ˜
    no_task_start = None  # ì—°ì†ëœ êµ¬ê°„ ì‹œì‘ì 
    no_task_end = None  # ì—°ì†ëœ êµ¬ê°„ ëì 

    while True:
        # ì›ë³¸ê³¼ ì²˜ë¦¬ëœ ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì½ê¸°
        ret_orig, frame_orig = cap_orig.read()
        ret_proc, frame_proc = cap_proc.read()

        # ë” ì´ìƒ ì½ì„ í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
        if not ret_orig or not ret_proc:
            break  # í”„ë ˆì„ ë

        # í˜„ì¬ í”„ë ˆì„ì˜ task ì°¾ê¸°
        current_task = next((t for t in tasks if t['seq'] == current_seq), None)

        if not current_task:  # Taskê°€ ì—†ëŠ” ê²½ìš°
            if no_task_start is None:
                no_task_start = current_seq  # ì²˜ìŒ ë°œê²¬í•œ ê²½ìš° ì‹œì‘ì  ì„¤ì •
            no_task_end = current_seq  # ëì  ê°±ì‹ 
            current_seq += 1
            continue  # current_taskê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µí•˜ì—¬ ì˜¤ë¥˜ ë°©ì§€

        # ì´ì „ê¹Œì§€ ì—°ì†ëœ "No task found" í”„ë ˆì„ì´ ìˆì—ˆë‹¤ë©´ ë¡œê·¸ ì¶œë ¥
        if no_task_start is not None:
            if no_task_start == no_task_end:
                logger.info(f"No task found for frame {no_task_start}, skipping processing.")
            else:
                logger.info(f"No task found for frames {no_task_start} ~ {no_task_end}, skipping processing.")
            no_task_start = None  # ì´ˆê¸°í™”
            no_task_end = None


        logger.info(f"Processing frame {current_seq}")

        # í˜„ì¬ í”„ë ˆì„ ë³µì‚¬
        frame = frame_proc.copy()

        # ëª¨ìì´í¬ ì œê±°: ì›ë³¸ í”„ë ˆì„ì—ì„œ í•´ë‹¹ ì˜ì—­ì„ ë³µì‚¬
        for box in current_task['remove']:
            x1, y1, x2, y2 = box['x1'], box['y1'], box['x2'], box['y2']
            logger.debug(f"Removing mosaic at {x1},{y1},{x2},{y2}")
            frame[y1:y2, x1:x2] = frame_orig[y1:y2, x1:x2]

        # ëª¨ìì´í¬ ì¶”ê°€: ìƒˆë¡œìš´ ì˜ì—­ì— ëª¨ìì´í¬ ì ìš©
        for box in current_task['add']:
            x1, y1, x2, y2 = box['x1'], box['y1'], box['x2'], box['y2']
            logger.debug(f"Adding mosaic at {x1},{y1},{x2},{y2}")
            frame = mosaic(frame, (x1, y1, x2 - x1, y2 - y1))

        # ì¤‘ë³µ ë°©ì§€ ë° ì €ì¥ (ê°™ì€ í”„ë ˆì„ì´ ì—¬ëŸ¬ ë²ˆ ì €ì¥ë˜ì§€ ì•Šë„ë¡)
        if current_seq not in frame_map:
            frame_map[current_seq] = frame
            edited_frames.append((current_seq, frame))

        current_seq += 1  # ë‹¤ìŒ í”„ë ˆì„ìœ¼ë¡œ ì´ë™

    # ë§ˆì§€ë§‰ "No task found" í”„ë ˆì„ì´ ìˆì—ˆë‹¤ë©´ ë¡œê·¸ ì¶œë ¥
    if no_task_start is not None:
        if no_task_start == no_task_end:
            logger.info(f"No task found for frame {no_task_start}, skipping processing.")
        else:
            logger.info(f"No task found for frames {no_task_start} ~ {no_task_end}, skipping processing.")

    # ë¹„ë””ì˜¤ íŒŒì¼ ë‹«ê¸°
    cap_orig.release()
    cap_proc.release()
    logger.info(f"Total frames processed: {len(edited_frames)}")
    return edited_frames

# --------------------------------------------------------------------------------------------------------------

def extract_modified_intervals_and_frame(original_video, processed_video, tasks, output_dir, fps, uuid):
    """
    í¸ì§‘ì´ í•„ìš”í•œ êµ¬ê°„ì„ ì°¾ì•„ ì—°ì†ëœ í”„ë ˆì„ì€ ë¹„ë””ì˜¤ë¡œ, ë‹¨ì¼ í”„ë ˆì„ì€ ì´ë¯¸ì§€ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        original_video (str): ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        processed_video (str): ëª¨ìì´í¬ ì²˜ë¦¬ëœ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        tasks (list): compare_metadataì—ì„œ ë°˜í™˜ëœ ì‘ì—… ëª©ë¡
        output_dir (str): ì¶œë ¥ íŒŒì¼ë“¤ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        fps (int): ë¹„ë””ì˜¤ì˜ ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜

    Returns:
        tuple: (videos, single_frames) - í¸ì§‘ëœ ë¹„ë””ì˜¤ íŒŒì¼ ëª©ë¡ê³¼ ë‹¨ì¼ í”„ë ˆì„ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
    """
    # í”„ë ˆì„ í¸ì§‘ ìˆ˜í–‰
    edited_frames = process_frame(original_video, processed_video, tasks)

    if not edited_frames:
        return [], []

    videos = []          # ì €ì¥ëœ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    single_frames = []    # ì €ì¥ëœ ë‹¨ì¼ í”„ë ˆì„ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    current_sequence = [] # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì—°ì† í”„ë ˆì„ë“¤
    last_seq = edited_frames[0][0]  # ë§ˆì§€ë§‰ìœ¼ë¡œ ì²˜ë¦¬í•œ í”„ë ˆì„ ë²ˆí˜¸

    # í¸ì§‘ëœ í”„ë ˆì„ë“¤ì„ ìˆœíšŒí•˜ë©´ì„œ ì—°ì†ëœ êµ¬ê°„ ì°¾ê¸°
    for seq, frame in edited_frames:
        if seq == last_seq + 1 and current_sequence:
            # ì—°ì†ëœ í”„ë ˆì„ì¸ ê²½ìš° í˜„ì¬ ì‹œí€€ìŠ¤ì— ì¶”ê°€
            current_sequence.append(frame)
        else:
            # ì—°ì†ì´ ëŠê¸´ ê²½ìš° ì²˜ë¦¬
            if len(current_sequence) > 1:
                # 2ê°œ ì´ìƒì˜ í”„ë ˆì„ì€ ë¹„ë””ì˜¤ë¡œ ì €ì¥
                video_path = os.path.join(output_dir, f'edited_sequence_{last_seq-len(current_sequence)+1}_{last_seq}.mp4')
                join_frame(current_sequence, fps, video_path)
                videos.append(video_path)

                # MinIOì— ì—…ë¡œë“œ
                minio_path = f"{uuid}/temp/edited_sequence_{last_seq-len(current_sequence)+1}_{last_seq}.mp4"
                upload_to_minio(video_path, minio_path)

            elif len(current_sequence) == 1:
                # ë‹¨ì¼ í”„ë ˆì„ì€ ì´ë¯¸ì§€ë¡œ ì €ì¥
                frame_path = os.path.join(output_dir, f'edited_frame_{last_seq}.jpg')
                cv2.imwrite(frame_path, current_sequence[0])
                single_frames.append(frame_path)

                # MinIOì— ì—…ë¡œë“œ
                minio_path = f"{uuid}/temp/edited_frame_{last_seq}.jpg"
                upload_to_minio(frame_path, minio_path)


            # ìƒˆë¡œìš´ ì‹œí€€ìŠ¤ ì‹œì‘
            current_sequence = [frame]
        last_seq = seq

    # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ ì²˜ë¦¬
    if len(current_sequence) > 1:
        video_path = os.path.join(output_dir, f'edited_sequence_{last_seq-len(current_sequence)+1}_{last_seq}.mp4')
        join_frame(current_sequence, fps, video_path)
        videos.append(video_path)

        minio_path = f"{uuid}/temp/edited_sequence_{last_seq-len(current_sequence)+1}_{last_seq}.mp4"
        upload_to_minio(video_path, minio_path)

    elif len(current_sequence) == 1:
        frame_path = os.path.join(output_dir, f'edited_frame_{last_seq}.jpg')
        cv2.imwrite(frame_path, current_sequence[0])
        single_frames.append(frame_path)

        # MinIOì— ì—…ë¡œë“œ


        # MinIOì— ì—…ë¡œë“œ
        minio_path = f"{uuid}/temp/edited_frame_{last_seq}.jpg"
        upload_to_minio(frame_path, minio_path)


    return videos, single_frames

# --------------------------------------------------------------------------------------------------------------

def extract_frame_numbers(file_path):
    """edited_sequence_425_441.mp4 -> (425, 441)"""
    base = os.path.basename(file_path)
    parts = base.replace("edited_sequence_", "").replace(".mp4", "").split("_")
    return int(parts[0]), int(parts[1])

def extract_frame_number(file_path):
    """edited_frame_443.jpg -> 443"""
    base = os.path.basename(file_path)
    return int(base.replace("edited_frame_", "").replace(".jpg", ""))

# --------------------------------------------------------------------------------------------------------------

def merge_videos(original_video, edited_videos, edited_frames, final_output):
    """
    OpenCVì™€ FFmpegë¥¼ ê²°í•©í•˜ì—¬ í•„ìš”í•œ í”„ë ˆì„ë§Œ êµì²´í•œ í›„ ìµœì¢… ë¹„ë””ì˜¤ ìƒì„±
    """
    logger.info(f"ğŸ”„ Merging video: {original_video}")

    cap = cv2.VideoCapture(original_video)
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    logger.info(f"ğŸ¥ Original Video: {total_frames} frames, {fps} FPS, {width}x{height}")

    temp_output = "temp_output.mp4"

    # í¸ì§‘ëœ ë¹„ë””ì˜¤ & í”„ë ˆì„ ë§¤í•‘
    edited_video_map = {extract_frame_numbers(v): v for v in edited_videos}
    edited_frame_map = {extract_frame_number(f): f for f in edited_frames}

    logger.info(f"ğŸ“Œ Found {len(edited_video_map)} edited sequences and {len(edited_frame_map)} edited frames.")

    out = cv2.VideoWriter(temp_output, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

    frame_idx = 0
    while frame_idx < total_frames:
        ret, frame = cap.read()
        if not ret:
            break

        frame_idx += 1

        #  1ï¸âƒ£ edited_frame_*.jpgê°€ ìˆëŠ” ê²½ìš° êµì²´
        if frame_idx in edited_frame_map:
            edited_frame = cv2.imread(edited_frame_map[frame_idx])
            frame = cv2.resize(edited_frame, (width, height))

        #  2ï¸âƒ£ edited_sequence_*.mp4ì˜ êµ¬ê°„ì— í•´ë‹¹í•˜ë©´ í•´ë‹¹ ì˜ìƒì—ì„œ ê°€ì ¸ì™€ êµì²´
        for (start_seq, end_seq), video_path in edited_video_map.items():
            if start_seq <= frame_idx <= end_seq:
                edit_cap = cv2.VideoCapture(video_path)
                frame_offset = frame_idx - start_seq  # í•´ë‹¹ ë¹„ë””ì˜¤ì˜ ëª‡ ë²ˆì§¸ í”„ë ˆì„ì¸ì§€ ê³„ì‚°
                edit_cap.set(cv2.CAP_PROP_POS_FRAMES, frame_offset)
                ret_edit, edited_frame = edit_cap.read()
                edit_cap.release()

                if ret_edit:
                    frame = cv2.resize(edited_frame, (width, height))
                break  # ë®ì–´ì”Œì› ìœ¼ë©´ ì¢…ë£Œ

        out.write(frame)

    cap.release()
    out.release()

    #  ğŸ¥ FFmpegë¡œ ìµœì¢… ì••ì¶• (ì˜¤ë””ì˜¤ ìœ ì§€)
    cmd = [
        "ffmpeg",
        "-y",
        "-i", temp_output,
        "-i", original_video,  # ì›ë³¸ì—ì„œ ì˜¤ë””ì˜¤ ìœ ì§€
        "-c:v", "libx264",
        "-c:a", "copy",
        "-map", "0:v:0",
        "-map", "1:a:0?",
        final_output
    ]
    subprocess.run(cmd, check=True)

    #  ì„ì‹œ íŒŒì¼ ì‚­ì œ
    os.remove(temp_output)

    logger.info(f" Final merged video saved: {final_output}")

# --------------------------------------------------------------------------------------------------------------


# Kafka ì„¤ì •
KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"
REQUEST_TOPIC = "video-processing-requests"
RESPONSE_TOPIC = "video-processing-responses"

# --------------------------------------------------------------------------------------------------------------

def process_kafka_message(message):
    """Kafka ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ ì €ì¥"""
    try:
        uuid = message.get("requestId")
        operation = message.get("operation")  # split OR merge
        bucket_name = message.get("bucket_name", "di-bucket")
        output_dir = os.path.join("output", uuid)  # UUIDë³„ output ë””ë ‰í† ë¦¬ ìƒì„±

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)
        if not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)

        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        original_local_path = os.path.join(output_dir, "original.mp4")
        processed_local_path = os.path.join(output_dir, "processed.mp4")
        metadata_local_path = os.path.join(output_dir, "metadata.json")
        edited_metadata_local_path = os.path.join(output_dir, "edited_metadata.json")
        final_output_path = os.path.join(output_dir, "final.mp4")

        if operation == "split":
            print("ğŸš€ ë¹„ì‹ë³„ ì²˜ë¦¬ ì‹œì‘ (split)")
            # ì›ë³¸ ì˜ìƒ ë‹¤ìš´ë¡œë“œ
            download_from_minio(f"{uuid}/original.mp4", original_local_path)

            # ì°¸ì¡° ì´ë¯¸ì§€ ì„¤ì •
            reference_image_paths = ["front_face.jpg", "side_face1.jpg", "side_face2.jpg", "side_face3.jpg",
                                     "side_face6.jpg"]

            # ì–¼êµ´ ì¸ì½”ë”© ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±
            reference_encodings = []

            # ì´ë¯¸ì§€ íŒŒì¼ì„ í•˜ë‚˜ì”© ë¶ˆëŸ¬ì˜¤ê¸°
            for reference_image_path in reference_image_paths:
                reference_image = face_recognition.load_image_file(reference_image_path)
                encodings = face_recognition.face_encodings(reference_image, num_jitters=10)

                # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì€ ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥í•˜ê³  ìŠ¤í‚µ
                if not encodings:
                    print(
                        f"Error: Could not encode the reference image at {reference_image_path}. Skipping this image.")
                    continue  # ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ ë„˜ì–´ê°

                # ì •ìƒì ìœ¼ë¡œ ì–¼êµ´ì´ ê°ì§€ëœ ê²½ìš° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                reference_encodings.append(encodings[0])
                print(f"Successfully loaded face encoding from {reference_image_path}")

            # ëª¨ë“  ì¸ì½”ë”©ì´ ì‹¤íŒ¨í–ˆì„ ê²½ìš° ì—ëŸ¬ ë°˜í™˜
            if not reference_encodings:
                print("No valid reference encodings found! Exiting process.")
                return {"status": "error", "message": "No valid reference encodings available"}

            # ì˜ìƒ ì²˜ë¦¬ ë° JSON ìƒì„±
            json_output_path = process_video(original_local_path, processed_local_path, reference_encodings)

            # ì²˜ë¦¬ëœ ì˜ìƒ ë° JSON ì—…ë¡œë“œ
            upload_to_minio(processed_local_path, f"{uuid}/processed.mp4")
            upload_to_minio(json_output_path, f"{uuid}/metadata.json")

            return {
                "status": "success",
                "uuid": uuid,
                "processed_video_url": f"http://localhost:9000/{bucket_name}/{uuid}/processed.mp4",
                "metadata_url": f"http://localhost:9000/{bucket_name}/{uuid}/metadata.json",
                "message": "Video processed and uploaded"
            }

        # operationì´ "merge"ì´ë©´ ìµœì¢… í¸ì§‘ë³¸ ìƒì„±
        elif operation == "merge":
            print("ğŸš€ ìµœì¢… ì˜ìƒ ë³‘í•© ì‹œì‘ (merge)")

            # í•„ìš”í•œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            download_from_minio(f"{uuid}/processed.mp4", processed_local_path)
            download_from_minio(f"{uuid}/metadata.json", metadata_local_path)
            download_from_minio(f"{uuid}/edited_metadata.json", edited_metadata_local_path)

            # í¸ì§‘ì´ í•„ìš”í•œ ì‘ì—… í™•ì¸
            tasks = compare_metadata(metadata_local_path, edited_metadata_local_path)

            if tasks is None:
                logger.error("compare_metadata() returned None! Aborting merge process.")
                return {"status": "error", "message": "Metadata comparison failed"}

            if not tasks:
                # ë³€ê²½ì‚¬í•­ì´ ì—†ëŠ” ê²½ìš° processed.mp4ë¥¼ ê·¸ëŒ€ë¡œ ìµœì¢…ë³¸ìœ¼ë¡œ ì‚¬ìš©
                os.rename(processed_local_path, final_output_path)
            else:
                # ì›ë³¸ ë‹¤ìš´ë¡œë“œ (ëª¨ìì´í¬ ì œê±°ë¥¼ ìœ„í•´ í•„ìš”)
                download_from_minio(f"{uuid}/original.mp4", original_local_path)

                # í¸ì§‘ëœ êµ¬ê°„ ì¶”ì¶œ
                with open(metadata_local_path) as f:
                    metadata = json.load(f)
                    fps = metadata['fps']

                videos, frames = extract_modified_intervals_and_frame(
                    original_local_path,
                    processed_local_path,
                    tasks,
                    output_dir,
                    fps,
                    uuid
                ) or ([], [])

                if videos is None:
                    videos = []
                if frames is None:
                    frames = []

                if not videos and not frames:
                    logger.info("No edited frames found. Using processed.mp4 as final output.")
                    os.rename(processed_local_path, final_output_path)



                # ìµœì¢… ì˜ìƒ ë³‘í•©
                merge_videos(processed_local_path, videos, frames, final_output_path)
                logger.info(f"Merge operation completed successfully for UUID: {uuid}")

            # ìµœì¢… ì˜ìƒ ì—…ë¡œë“œ
            upload_to_minio(final_output_path, f"{uuid}/final.mp4")

            return {
                "status": "success",
                "uuid": uuid,
                "final_video_url": f"http://localhost:9000/{bucket_name}/{uuid}/final.mp4",
                "message": "Final video merged and uploaded"
            }

        else:
            return {"status": "error", "message": f"Unknown operation: {operation}"}

    except Exception as e:
        return {"status": "error", "message": str(e)}

# --------------------------------------------------------------------------------------------------------------

def consume_and_process():
    """Kafka ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•˜ê³  ì²˜ë¦¬."""
    consumer = KafkaConsumer(
        REQUEST_TOPIC,
        bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
        group_id="video-processing-group",
        value_deserializer=lambda m: json.loads(m.decode("utf-8"))
    )
    producer = KafkaProducer(
        bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
        value_serializer=lambda m: json.dumps(m).encode("utf-8")
    )

    for message in consumer:
        msg_value = message.value
        print(f"Received message: {msg_value}")

        result = process_kafka_message(msg_value)

        producer.send(RESPONSE_TOPIC, value=result)
        print(f"Sent result: {result}")


if __name__ == "__main__":
    consume_and_process()
